{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CartPole-v0\n",
    "\"A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.\"\n",
    "\n",
    "\n",
    "The following is extracted from: https://github.com/openai/gym/wiki/CartPole-v0\n",
    "\n",
    "## Observation\n",
    "Type: Box(4)\n",
    "\n",
    "| Num |      Observation     |    Min   |   Max   |\n",
    "|:---:|:--------------------:|:--------:|:-------:|\n",
    "| 0   | Cart Position        | -2.4     | 2.4     |\n",
    "| 1   | Cart Velocity        | -Inf     | Inf     |\n",
    "| 2   | Pole Angle           | ~ -41.8° | ~ 41.8° |\n",
    "| 3   | Pole Velocity At Tip | -Inf     | Inf     |\n",
    "\n",
    "## Action\n",
    "Type: Discrete(2)\n",
    "| Num |      Observation     |    Min   |   Max   |\n",
    "|:---:|:--------------------:|:--------:|:-------:|\n",
    "| 0   | Cart Position        | -2.4     | 2.4     |\n",
    "| 1   | Cart Velocity        | -Inf     | Inf     |\n",
    "| 2   | Pole Angle           | ~ -41.8° | ~ 41.8° |\n",
    "| 3   | Pole Velocity At Tip | -Inf     | Inf     |\n",
    "Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it.\n",
    "\n",
    "## Reward\n",
    "Reward is 1 for every step taken, including the termination step. The threshold is 475 for v1.\n",
    "\n",
    "\n",
    "## Starting State\n",
    "All observations are assigned a uniform random value between ±0.05.\n",
    "\n",
    "## Episode Termination\n",
    "1. Pole Angle is more than ±12°\n",
    "2. Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\n",
    "3. Episode length is greater than 200 (500 for v1).\n",
    "\n",
    "## Solved Requirements\n",
    "Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://gym.openai.com/envs/CartPole-v0/ &  https://gym.openai.com/docs/ :\n",
    "\n",
    "Loop: Each timestep, the agent chooses an action, the environment returns an observation and a reward. The process starts by calling reset() which returns an intitial observation:\n",
    "    \"on each episode, and at every step, an action is chosen based on the current state and a policy based on the action-value function Q. After taking the action, we receive a reward and arrive at the next state. This information is used to update the action-value function, and, after doing so, we make the next state our current state and follow through until we reach the final state of the final episode.\" - https://medium.com/@flomay/using-q-learning-to-solve-the-cartpole-balancing-problem-c0a7f47d3f9d\n",
    "\n",
    "**Step** returns 4 values:\n",
    "1. Observation is an environment specific object representing your observation of the environment e.g. pixel data from camera or board state in boardgame. \n",
    "2. Reward is a float. It is the amout of reward achieved by the prior action. The goal is to increase total reward. The reward scale varies between environments.\n",
    "3. Done is a boolean. Whether it is time to reset the environment. Most tasks are divided into episodes which terminate when done.\n",
    "4. Info (dict) provides diagnostic information for debugging.\n",
    "\n",
    "Every **environment** comes with an action_space and an observation_space, which describe the format of valid actions and observations. The Discrete space allows a fixed range of non-negative numbers e.g. valid **actions** are either 0 or 1.  The Box space represents and n-dimensional box so valid **observations** will be an array of 4 numbers.\n",
    "\n",
    "In CartPole, one of the actions applies force to the left and one applies force to the right\n",
    "\n",
    "\"Since this [Q learning] algorithm relies on updating a function for each existing pair of state and action, environments that have a high state-space become problematic. This is because we can approximate better the actual value of a state-action pair as we visit it more often. However, if we have many states or many actions to take, we distribute our visits among more pairs and it takes much longer to converge to the actual true values. \" - https://medium.com/@flomay/using-q-learning-to-solve-the-cartpole-balancing-problem-c0a7f47d3f9d \n",
    "\n",
    "The action-value function must be updated at every step of learning. The values for the pairs of state visited and action taken are updated. \n",
    " \n",
    "See also: https://medium.com/swlh/using-q-learning-for-openais-cartpole-v1-4a216ef237df\n",
    "Read https://medium.com/@flomay/using-q-learning-to-solve-the-cartpole-balancing-problem-c0a7f47d3f9d with https://github.com/JoeSnow7/Reinforcement-Learning/blob/master/Cartpole%20Q-learning.ipynb\n",
    "\n",
    "###### Goal: The way to choose the best action for every state in the environment.\n",
    "- Gym presets the reward ie cannot change reward to solve these problems. \n",
    "- You can change how the q-table is populated. You can change how the Q-table is calculated on each step. e.g. Keep track of the reward for each step and long term. Alter learning rate and discount rate.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This whole file's source code is copied from: https://github.com/JoeSnow7/Reinforcement-Learning/blob/master/Cartpole%20Q-learning.ipynb"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Buckets  \n",
    "***Group several values of each of the variables into the same “bucket” and treat them as similar state***\n",
    "\n",
    "Since the Q Learning \"algorithm relies on updating a function for each existing pair of state and action, environments that have a high state-space become problematic. This is because we can approximate better the actual value of a state-action pair as we visit it more often. However, if we have many states or many actions to take, we distribute our visits among more pairs and it takes much longer to converge to the actual true values. \n",
    "\n",
    "The CartPole environment gives us the position of the cart, its velocity, the angle of the pole and the velocity at the tip of the pole as descriptors of the state. However, all of these are continuous variables. \n",
    "\n",
    "To be able to solve this problem, we need to discretize these states since otherwise, it would take forever to get values for each of the possible combinations of each state, despite them being bounded. \n",
    "\n",
    "The solution is to group several values of each of the variables into the same “bucket” and treat them as similar states. The agent implemented for this problem uses 3, 3, 6, and 6 buckets respectively.\n",
    "\n",
    "This discretize_state(obs) function takes an observation from the environment and transforms it into something more manageable. By combining states that are very similar and treating it as the same, we have reduced the state space and made the Q-table smaller and easier to fill.\"\n",
    "\n",
    "-https://medium.com/@flomay/using-q-learning-to-solve-the-cartpole-balancing-problem-c0a7f47d3f9d"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://medium.com/@flomay/using-q-learning-to-solve-the-cartpole-balancing-problem-c0a7f47d3f9d\n",
    "\n",
    "\"Since this algorithm relies on updating a function for each existing pair of state and action, environments that have a high state-space become problematic. This is because we can approximate better the actual value of a state-action pair as we visit it more often. However, if we have many states or many actions to take, we distribute our visits among more pairs and it takes much longer to converge to the actual true values. The CartPole environment gives us the position of the cart, its velocity, the angle of the pole and the velocity at the tip of the pole as descriptors of the state. However, all of these are continuous variables. To be able to solve this problem, we need to discretize these states since otherwise, it would take forever to get values for each of the possible combinations of each state, despite them being bounded. The solution is to group several values of each of the variables into the same “bucket” and treat them as similar states. The agent implemented for this problem uses 3, 3, 6, and 6 buckets respectively.\"\n",
    "\n",
    "https://github.com/IsaacPatole/CartPole-v0-using-Q-learning-SARSA-and-DNN/blob/master/Qlearning_for_cartpole.py\n",
    "    \"\"\"\n",
    "        Takes an observation of the environment and aliases it.\n",
    "        By doing this, very similar observations can be treated\n",
    "        as the same and it reduces the state space so that the \n",
    "        Q-table can be smaller and more easily filled.\n",
    "        \n",
    "        Input:\n",
    "        obs (tuple): Tuple containing 4 floats describing the current\n",
    "                     state of the environment.\n",
    "        \n",
    "        Output:\n",
    "        discretized (tuple): Tuple containing 4 non-negative integers smaller \n",
    "                             than n where n is the number in the same position\n",
    "                             in the buckets list.\n",
    "        \"\"\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "\"\"\"\n",
    "Base code taken from: \n",
    "https://github.com/IsaacPatole/CartPole-v0-using-Q-learning-SARSA-and-DNN/blob/master/Qlearning_for_cartpole.py\n",
    "\"\"\"\n",
    "\n",
    "class CartPoleQAgent():\n",
    "    def __init__(self, buckets=(3, 3, 6, 6), #buckets: the position of the cart, its velocity, the angle of the pole and the velocity at the tip of the pole as descriptors of the state\n",
    "                 num_episodes=500, min_lr=0.1, #min-lr is the learning rate. #Between 0 and 1. How quickly the agent abandons the previous value in the Q table for the new value. 0: Agent learns nothing and only uses prior knowledge. 1: Agent considers only the most recent information.\n",
    "                 min_epsilon=0.1, discount=1.0, decay=25): #min epsilon is the exploration rate. #1: Guaranteed that agent starts the game by 100% exploring the environment #0: Agent does not explore at all. Agent only exploits (chooses actions to get max points)\n",
    "                                                            #discount is the discount rate. Determines the importance of future rewards. 0 agent is short sighted and sees only current reqards. Appoaching 1, the agent strives for long term rewards.\n",
    "                                                            #decay is the  exploration_decay_rate\n",
    "        self.buckets = buckets\n",
    "        self.num_episodes = num_episodes\n",
    "        self.min_lr = min_lr\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.discount = discount\n",
    "        self.decay = decay\n",
    "\n",
    "        self.env = gym.make('CartPole-v0')\n",
    "        \n",
    "        # This is the action-value function being initialized to 0's\n",
    "        self.Q_table = np.zeros(self.buckets + (self.env.action_space.n,))\n",
    "\n",
    "        # [position, velocity, angle, angular velocity]\n",
    "        self.upper_bounds = [self.env.observation_space.high[0], 0.5, self.env.observation_space.high[2], math.radians(50) / 1.]\n",
    "        self.lower_bounds = [self.env.observation_space.low[0], -0.5, self.env.observation_space.low[2], -math.radians(50) / 1.]\n",
    "        \n",
    "        #\n",
    "        self.steps = np.zeros(self.num_episodes)\n",
    "        \n",
    "        \n",
    "\n",
    "    def discretize_state(self, obs):\n",
    "        \"\"\"\n",
    "        Takes an observation of the environment and aliases it.\n",
    "        By doing this, very similar observations can be treated\n",
    "        as the same and it reduces the state space so that the \n",
    "        Q-table can be smaller and more easily filled.\n",
    "        \n",
    "        Input:\n",
    "        obs (tuple): Tuple containing 4 floats describing the current\n",
    "                     state of the environment.\n",
    "        \n",
    "        Output:\n",
    "        discretized (tuple): Tuple containing 4 non-negative integers smaller \n",
    "                             than n where n is the number in the same position\n",
    "                             in the buckets list.\n",
    "        \"\"\"\n",
    "        discretized = list()\n",
    "        for i in range(len(obs)):\n",
    "            scaling = ((obs[i] + abs(self.lower_bounds[i])) \n",
    "                       / (self.upper_bounds[i] - self.lower_bounds[i]))\n",
    "            new_obs = int(round((self.buckets[i] - 1) * scaling))\n",
    "            new_obs = min(self.buckets[i] - 1, max(0, new_obs))\n",
    "            discretized.append(new_obs)\n",
    "        return tuple(discretized)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"\n",
    "        Implementation of e-greedy algorithm. Returns an action (0 or 1).\n",
    "        \n",
    "        Input:\n",
    "        state (tuple): Tuple containing 4 non-negative integers within\n",
    "                       the range of the buckets.\n",
    "        \n",
    "        Output:\n",
    "        (int) Returns either 0 or 1\n",
    "        \"\"\"\n",
    "        if (np.random.random() < self.epsilon):\n",
    "            return self.env.action_space.sample() \n",
    "        else:\n",
    "            return np.argmax(self.Q_table[state])\n",
    "        \n",
    "    def get_action(self, state, e):\n",
    "        \"\"\"\n",
    "        Another policy based on the Q-table. Slight variation from \n",
    "        e-greedy. It assumes the state fed hasn't been discretized and \n",
    "        returns a vector with probabilities for each action.\n",
    "        \n",
    "        Input: \n",
    "        state (tuple): Contains the 4 floats used to describe\n",
    "                       the current state of the environment.\n",
    "        e (int): Denotes the episode at which the agent is supposed\n",
    "                 to be, helping balance exploration and exploitation.\n",
    "                 \n",
    "        Output:\n",
    "        action_vector (numpy array): Vector containing the probability\n",
    "                                     of each action being chosen at the\n",
    "                                     current state.\n",
    "        \"\"\"\n",
    "        obs = self.discretize_state(state)\n",
    "        action_vector = self.Q_table[obs]\n",
    "        epsilon = self.get_epsilon(e)\n",
    "        action_vector = self.normalize(action_vector, epsilon)\n",
    "        return action_vector\n",
    "\n",
    "    def normalize(self, action_vector, epsilon):\n",
    "        \"\"\"\n",
    "        Returns a vector with components adding to 1. Ensures \n",
    "        \n",
    "        Input:\n",
    "        action_vector (numpy array): Contains expected values for each\n",
    "                                     action at current state from Q-table.\n",
    "        epsilon (float): Chances that the e-greedy algorithm would \n",
    "                         choose an action at random. With this pol\n",
    "        \n",
    "        Output:\n",
    "        new_vector (numpy array): Vector containing the probability\n",
    "                                  of each action being chosen at the\n",
    "                                  current state.\n",
    "        \"\"\"\n",
    "        \n",
    "        total = sum(action_vector)\n",
    "        new_vector = (1-epsilon)*action_vector/(total)\n",
    "        new_vector += epsilon/2.0\n",
    "        return new_vector\n",
    "\n",
    "    def update_q(self, state, action, reward, new_state):\n",
    "        \"\"\"\n",
    "        Updates Q-table using the rule as described by Sutton and Barto in\n",
    "        Reinforcement Learning.\n",
    "        \"\"\"\n",
    "        self.Q_table[state][action] += (self.learning_rate * \n",
    "                                        (reward \n",
    "                                         + self.discount * np.max(self.Q_table[new_state]) \n",
    "                                         - self.Q_table[state][action]))\n",
    "\n",
    "    def get_epsilon(self, t):\n",
    "        \"\"\"Gets value for epsilon. It declines as we advance in episodes.\"\"\"\n",
    "        # Ensures that there's almost at least a min_epsilon chance of randomly exploring\n",
    "        return max(self.min_epsilon, min(1., 1. - math.log10((t + 1) / self.decay)))\n",
    "\n",
    "    def get_learning_rate(self, t):\n",
    "        \"\"\"Gets value for learning rate. It declines as we advance in episodes.\"\"\"\n",
    "        # Learning rate also declines as we add more episodes\n",
    "        return max(self.min_lr, min(1., 1. - math.log10((t + 1) / self.decay)))\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains agent making it go through the environment and choose actions\n",
    "        through an e-greedy policy and updating values for its Q-table. The \n",
    "        agent is trained by default for 500 episodes with a declining \n",
    "        learning rate and epsilon values that with the default values,\n",
    "        reach the minimum after 198 episodes.\n",
    "        \"\"\"\n",
    "        # Looping for each episode in the range\n",
    "        for e in range(self.num_episodes):\n",
    "            # Initializes the state\n",
    "            current_state = self.discretize_state(self.env.reset())\n",
    "\n",
    "            self.learning_rate = self.get_learning_rate(e)\n",
    "            self.epsilon = self.get_epsilon(e)\n",
    "            done = False\n",
    "            \n",
    "            # Looping for each step\n",
    "            while not done:\n",
    "                self.steps[e] += 1\n",
    "                # Choose A from S\n",
    "                action = self.choose_action(current_state)\n",
    "                # Take action\n",
    "                obs, reward, done, _ = self.env.step(action)\n",
    "                new_state = self.discretize_state(obs)\n",
    "                # Update Q(S,A)\n",
    "                self.update_q(current_state, action, reward, new_state)\n",
    "                current_state = new_state\n",
    "                \n",
    "                # We break out of the loop when done is False which is\n",
    "                # a terminal state.\n",
    "        print('Finished training!')\n",
    "    \n",
    "    def plot_learning(self):\n",
    "        \"\"\"\n",
    "        Plots the number of steps at each episode and prints the\n",
    "        amount of times that an episode was successfully completed.\n",
    "        \"\"\"\n",
    "        sns.lineplot(range(len(self.steps)),self.steps)\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.ylabel(\"Steps\")\n",
    "        plt.show()\n",
    "        t = 0\n",
    "        for i in range(self.num_episodes):\n",
    "            if self.steps[i] == 200:\n",
    "                t+=1\n",
    "        print(t, \"episodes were successfully completed.\")\n",
    "        \n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Runs an episode while displaying the cartpole environment.\"\"\"\n",
    "        self.env = gym.wrappers.Monitor(self.env,'CartPole-v0')\n",
    "        t = 0\n",
    "        done = False\n",
    "        current_state = self.discretize_state(self.env.reset())\n",
    "        while not done:\n",
    "                self.env.render()\n",
    "                t = t+1\n",
    "                action = self.choose_action(current_state)\n",
    "                obs, reward, done, _ = self.env.step(action)\n",
    "                new_state = self.discretize_state(obs)\n",
    "                current_state = new_state   \n",
    "        return t\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "def load_q_learning():\n",
    "    agent = CartPoleQAgent()\n",
    "    agent.train()\n",
    "    agent.plot_learning()\n",
    "    return agent\n",
    "    \n",
    "agent = load_q_learning()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "330 episodes were successfully completed.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}