{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### FrozenLake-v1\n",
    "\"The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile.\"\n",
    "https://gym.openai.com/envs/FrozenLake-v0/ \n",
    "\n",
    "The below is Frozen Lake set to slippery and random. The agent will not do well if it can only see its immediate surroundings in a random map but if it can see the whole map, it can do well with training and avoid holes ie it can avoid holes if it can see them before moving to hole.\n",
    "\n",
    "#### SUMMARY\n",
    "Environment: The whole grid world including all squares e.g. 4x4 = 16 squares\n",
    "State: One square\n",
    "Agent: Can occupy one state at a time, can perform actions (up, down, left, right). As the agent travels and explores the environment it will work out th ebest policy.\n",
    "Reward: +1 when finding the fisbee goal, -1 when falling in a hole.Can implement a negative reward eg -0.1 per step i.e. higher reward if reached faster.\n",
    "Policy: Map & information about what action to take in a particular state. The best policy is to thake the best action in a particular state. Find a policy that allows agent to gain maxium reward.\n",
    "\n",
    "###### Q-TABLE (reward table)\n",
    "As the agent expolores, it records the best action to take for each state (square) in the Q-Table \n",
    "e.g. If you start in state C1 and the reward is at A1, it is best to move up when in square C1. From B1 it is then best to move up and get the reward at A1.\n",
    "\n",
    "###### Goal: The way to choose the best action fr every state in the environment.\n",
    "- Gym presets the reward ie cannot change reward to solve these problems. \n",
    "- You can change how the q-table is populated. You can change how the Q-table is calculated on each step. e.g. Keep track of the reward for each step and long term.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "gc.disable() #Disable automatic garbage collection."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=True )\n",
    "action_space_size = env.action_space.n\n",
    "state_space_size = env.observation_space.n\n",
    "q_table = np.zeros((state_space_size, action_space_size))\n",
    "print(\"The dimensions of the q table are: \", q_table.shape)\n",
    "print(q_table)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The dimensions of the q table are:  (16, 4)\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "num_episodes = 20000\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "learning_rate = 0.9 #0.03 #Between 0 and 1. How quickly the agent abandons the previous value in the Q table for the new value. 0: Agent learns nothing and only uses prior knowledge. 1: Agent considers only the most recent information.\n",
    "discount_rate = 0.9 #0.97 Determines the importance of future rewards. 0 agent is short sighted and seees only current reqards. Appoaching 1, the agent strives for long term rewards.\n",
    "\n",
    "exploration_rate = 1\n",
    "max_exploration_rate = 1    #1: Guaranteed that agent starts the game by 100% exploring the environment\n",
    "min_exploration_rate = 0    #0: Agent does not explore at all. Agent only exploits (chooses actions to get max points)\n",
    "exploration_decay_rate = 0.001\n",
    "\n",
    "#Change state to represent the whole grid rather than one tile"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "rewards_all_episodes = []\n",
    "\n",
    "# Q-Learning algorithm\n",
    "for episode in range(num_episodes):\n",
    "    \n",
    "    random_map = generate_random_map(size=4, p=0.8) # p is the probability of where the holes are\n",
    "    env = gym.make('FrozenLake-v1', is_slippery=True, desc=random_map)\n",
    "    state = env.reset()\n",
    "\n",
    "    done = False\n",
    "    rewards_current_episode = 0\n",
    "\n",
    "    for step in range (max_steps_per_episode):\n",
    "\n",
    "        # Exploration / Exploitation trade-off\n",
    "        exploration_rate_threshold = random.uniform(0, 1)\n",
    "        if exploration_rate_threshold > exploration_rate:\n",
    "            action = np.argmax(q_table[state,:])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        q_table[state, action] = q_table[state, action] * (1 - learning_rate) + \\\n",
    "            learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))\n",
    "\n",
    "        state = new_state\n",
    "        rewards_current_episode += reward\n",
    "\n",
    "        if done == True:\n",
    "            break\n",
    "\n",
    "    # Exploration rate decay\n",
    "    exploration_rate = min_exploration_rate + \\\n",
    "        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n",
    "\n",
    "    rewards_all_episodes.append(rewards_current_episode)\n",
    "\n",
    "# Calculate reward across all episodes\n",
    "rewards_per_thousand_episodes = np.split(np.array(rewards_all_episodes), num_episodes / 1000)\n",
    "count = 1000\n",
    "count_plot = [] #for plotting\n",
    "r_plot = [] #for plotting\n",
    "print(\"*** AVG reward per 1000 episodes***\\n\")\n",
    "for r in rewards_per_thousand_episodes:\n",
    "    print(count, \": \", str(sum(r/1000)))\n",
    "    count_plot.append(count) #for plotting. \n",
    "    r_plot.append(sum(r/1000)) #for plotting\n",
    "    count += 1000\n",
    "\n",
    "\n",
    "# Print Q table\n",
    "print(\"\\n\\n *** Q-table ***\\n\")\n",
    "print(q_table)\n",
    "\n",
    "\n",
    "#Plot results \n",
    "%matplotlib inline\n",
    "#Name x-axis, y-axis and whole graph\n",
    "plt.xlabel(\"episodes\")\n",
    "plt.ylabel(\"average rewards\")\n",
    "plt.title(\"FROZEN LAKE: AVG reward per 1000 episodes\")\n",
    "# Plotting all the graphs\n",
    "plt.plot(count_plot, r_plot, color=\"darkviolet\", label = \"Push\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "#Load the display window\n",
    "plt.show\n",
    "#set y-axis limit\n",
    "plt.ylim([0, 1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** AVG reward per 1000 episodes***\n",
      "\n",
      "1000 :  0.17100000000000012\n",
      "2000 :  0.17100000000000012\n",
      "3000 :  0.17300000000000013\n",
      "4000 :  0.22900000000000018\n",
      "5000 :  0.21900000000000017\n",
      "6000 :  0.22200000000000017\n",
      "7000 :  0.23000000000000018\n",
      "8000 :  0.2620000000000002\n",
      "9000 :  0.20600000000000016\n",
      "10000 :  0.21600000000000016\n",
      "11000 :  0.2640000000000002\n",
      "12000 :  0.2410000000000002\n",
      "13000 :  0.21200000000000016\n",
      "14000 :  0.21500000000000016\n",
      "15000 :  0.21400000000000016\n",
      "16000 :  0.21900000000000017\n",
      "17000 :  0.21700000000000016\n",
      "18000 :  0.20800000000000016\n",
      "19000 :  0.20700000000000016\n",
      "20000 :  0.22800000000000017\n",
      "\n",
      "\n",
      " *** Q-table ***\n",
      "\n",
      "[[0.0332137  0.22858155 0.03391567 0.0347093 ]\n",
      " [0.03257074 0.25013484 0.0333492  0.03343517]\n",
      " [0.04763185 0.31873318 0.04678817 0.04019886]\n",
      " [0.35286779 0.04535536 0.04649199 0.04699407]\n",
      " [0.03900777 0.03636411 0.50536976 0.03310691]\n",
      " [0.04061397 0.10200513 0.03899264 0.04112443]\n",
      " [0.05295157 0.05669178 0.41803098 0.05699151]\n",
      " [0.06226115 0.84325777 0.06118828 0.05780905]\n",
      " [0.03594791 0.03878732 0.61023151 0.03767286]\n",
      " [0.04053996 0.04524441 0.5663388  0.03809564]\n",
      " [0.05486155 0.06021973 0.46134037 0.0527514 ]\n",
      " [0.06109676 0.35288985 0.06664272 0.0638328 ]\n",
      " [0.03481916 0.03720261 0.03610011 0.17392565]\n",
      " [0.0416627  0.04038403 0.2419703  0.04070327]\n",
      " [0.065713   0.06907426 0.06862279 0.95137343]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "metadata": {},
     "execution_count": 99
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "\n",
    "for episode in range(10):\n",
    "    #random map each episode\n",
    "    random_map = generate_random_map(size=4, p=0.8)\n",
    "    env = gym.make('FrozenLake-v1', is_slippery=True, desc=random_map) #generates random map for each episode\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    print(\"*****EPISODE \", episode+1, \"*****\\n\\n\\n\\n\")\n",
    "    time.sleep(1) #changed from 1\n",
    "\n",
    "    for step in range(max_steps_per_episode):        \n",
    "        clear_output(wait=True)\n",
    "        env.render()\n",
    "        time.sleep(0.3) #changed from 0.3\n",
    "        \n",
    "        action = np.argmax(q_table[state,:])        \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            clear_output(wait=True)\n",
    "            env.render()\n",
    "            if reward == 1:\n",
    "                print(\"****You reached the goal!****\")\n",
    "                time.sleep(1) #changed from 3\n",
    "            else:\n",
    "                print(\"****You fell through a hole!****\")\n",
    "                time.sleep(1) #changed from 3\n",
    "            clear_output(wait=True)\n",
    "            break\n",
    "            \n",
    "        state = new_state\n",
    "        \n",
    "env.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (Down)\n",
      "SFFH\n",
      "FF\u001b[41mH\u001b[0mF\n",
      "FFFF\n",
      "FFFG\n",
      "****You fell through a hole!****\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "\n",
    "It is not \"possible to learn an optimal policy for the average environment\" - https://stats.stackexchange.com/questions/453150/can-an-agent-be-trained-in-a-completely-random-environment-the-rules-and-action\n",
    "\n",
    "\"The distribution of purely random numbers is uniform so there's nothing to learn....Reinforcement learning assumes your environment is stationary. The underlying probability distribution of your environment (both transition and reward function) must be held constant throughout the learning process. Sure, RL and DRL can deal with some slightly non-stationary problems, but it struggles at that. Markov Decision Processes (MDPs) and Partially-Observable MDPs assume stationarity. So value-based algorithms, which are specialized in exploiting MDP-like environments, such as SARSA, Q-learning, DQN, DDQN, Dueling DQN, etc., will have a hard time learning anything in non-stationary environments. The more you go towards policy-based algorithms, such as PPO, TRPO, or even better gradient-free, such as GA, CEM, etc., the better chance you have as these algorithms don't try to exploit this assumption. Also, playing with the learning rate would be essential to make sure the agent never stops learning..\" - https://stackoverflow.com/questions/52744919/is-reinforcement-learning-applicable-to-a-random-environment\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}